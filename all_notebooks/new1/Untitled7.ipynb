{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl.load(os.read(os.pwd/'git/'diss/'src/'main/'scala/\"import.sc\"))\n",
    "// repl.load(os.read(os.pwd/\"a.sc\"))\n",
    "repl.load(os.read(os.pwd/'git/'diss/'src/'main/'scala/\"a.scala\"))\n",
    "// repl.load(os.read(os.pwd/'git/'diss/'src/'main/'scala/\"b.sc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Diss._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  type Offset = Int\n",
    "  type Idx = Int\n",
    "  type Hash = (Int, Int)\n",
    "\n",
    "  def hash(str: String, seed: Int): Int = {\n",
    "    var res = 1\n",
    "    for (c <- str) {\n",
    "      res = res * seed + c.toInt\n",
    "    }\n",
    "\n",
    "    res\n",
    "  }\n",
    "\n",
    "  val fufloList: List[String] = List[String](\n",
    "    \"АФЛУБИН\",\n",
    "    \"КАГОЦЕЛ\",\n",
    "    \"АРБИДОЛ\",\n",
    "    \"АМИКСИН\",\n",
    "    \"АКТОВЕГИН\",\n",
    "    \"БЕТУЛИН\",\n",
    "    \"ВИТПРОСТ\",\n",
    "    \"ВИФЕРОН\",\n",
    "    \"ВОБЭНЗИМ\",\n",
    "    \"ГАЛАВИТ\",\n",
    "    \"ГРИППФЕРОН\",\n",
    "    \"ДЕТРАЛЕКС\",\n",
    "    \"ИМУНАЛ\",\n",
    "    \"ИМПАЗА\",\n",
    "    \"АНАФЕРОН\",\n",
    "    \"АРТРОФООН\",\n",
    "    \"ДИВАЗА\",\n",
    "    \"АФАЛА\",\n",
    "    \"АФАЛАЗА\",\n",
    "    \"ИМУНОФАН\",\n",
    "    \"ИНГАВИРИН\",\n",
    "    \"ИНГАРОН\",\n",
    "    \"ИНОЗИН\",\n",
    "    \"ИНСТЕНОН\",\n",
    "    \"ВИНПОЦЕТИН\",\n",
    "    \"КОРТЕКСИН\",\n",
    "    \"МАСТОДИНОН\",\n",
    "    \"МЕБИКАР\",\n",
    "    \"МИЛДРОНАТ\",\n",
    "    \"НОВОПАССИТ\",\n",
    "    \"ОКСОЛИН\",\n",
    "    \"ПАНАВИР\",\n",
    "    \"ПОЛИОКСИДОНИЙ\",\n",
    "    \"ПРЕДУКТАЛ\",\n",
    "    \"ПРОДИГИОЗАН\",\n",
    "    \"ТИМАЛИН\",\n",
    "    \"ТИМОГЕН\",\n",
    "    \"ТРОМБОВАЗИМ\",\n",
    "    \"ЦЕРЕБРОЛИЗИН\",\n",
    "    \"ЦИКЛОФЕРОН\",\n",
    "    \"МАГНИТОТЕРАПИЯ\",\n",
    "    \"ЛАЗЕРНОЕ ОБЛУЧЕНИЕ\",\n",
    "    \"СОЛЯНАЯ ПЕЩЕРА\",\n",
    "    \"ИРИДОДИАГНОСТИКА\",\n",
    "    \"ДИАГНОСТИКА ПО ФОЛЛЮ\",\n",
    "    \"ИГЛОТЕРАПИЯ\",\n",
    "    \"ЧЖЕНЬ ЦЗЮ ТЕРАПИЯ\",\n",
    "    \"БИОЛОГИЧЕСКАЯ ОБРАТНАЯ СВЯЗЬ\",\n",
    "    \"ГИПНОЗ\",\n",
    "    \"ГИПНОТИЧЕСКАЯ\",\n",
    "    \"ПСИХОАНАЛИЗ\",\n",
    "    \"ПСИХОАНАЛИТИЧЕСКАЯ\",\n",
    "    \"ОСТЕОПАТИЯ\",\n",
    "    \"МАНУАЛЬНАЯ ТЕРАПИЯ\",\n",
    "    \"ХИРОПРАКТИКА\",\n",
    "    \"АКУПУНКТУРА\",\n",
    "    \"ИГЛОРЕФЛЕКСОТЕРАПИЯ\",\n",
    "    \"РЕФЛЕКСОТЕРАПИЯ\",\n",
    "    \"ИГЛОУКАЛЫВАНИЕ\"\n",
    "  )\n",
    "\n",
    "  def hashT(str: String): Hash = {\n",
    "    (hash(str, 5), hash(str, 7))\n",
    "  }\n",
    "\n",
    "  lazy val windowSize = 6\n",
    "\n",
    "  def context(main: List[String], fufloList: List[String]): List[(String, Offset, Set[Hash], Set[Hash])] = {\n",
    "\n",
    "    val positions: List[(Offset, String)] = for {(word, idx) <- main.zipWithIndex\n",
    "                                                 badWord <- fufloList\n",
    "                                                 if matchWord(word, badWord)\n",
    "                                                 } yield {\n",
    "      (idx, badWord)\n",
    "    }\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = positions.map { case (offset, badWord) =>\n",
    "      val setbefore = main.slice(offset - 25, offset).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      val setafter = main.slice(offset, offset + 25).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      (badWord, offset, setbefore, setafter)\n",
    "    }\n",
    "\n",
    "    mainContext\n",
    "  }\n",
    "\n",
    "  def parseWork(work: List[String]): Map[Hash, Offset] = {\n",
    "    work.sliding(windowSize).zipWithIndex.map { case (lst, idx) => hashT(lst.mkString(\" \")) -> idx }.toMap\n",
    "  }\n",
    "\n",
    "  def normalize(value: String): List[String] = {\n",
    "    value.filter(ch => ch == ' ' || (ch >= 'а' && ch <= 'Я') || (ch >= '\\u0410' && ch <= '\\u044F') || ch.isDigit).toUpperCase.split(\" \").filter(_.nonEmpty).toList\n",
    "  }\n",
    "\n",
    "  def listContainsBad(values: List[String], badWord: String): Boolean = {\n",
    "    values.exists { word =>\n",
    "      matchWord(word, badWord)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def countNumbers(value: String): Int = {\n",
    "    value.filter(ch => ch == ' ' || ch.isDigit).split(\" \").count(_.nonEmpty)\n",
    "  }\n",
    "\n",
    "  def check2Works(main: List[String], mainContext: List[(String, Offset, Set[Hash], Set[Hash])], other: Map[Hash, Offset], otherText: List[String]): List[(String, String, String, String, String)] = {\n",
    "\n",
    "    val res: List[(String, String, String, Offset, String, String)] =\n",
    "      mainContext.flatMap { case (badWord, offset, setBefore, setAfter) =>\n",
    "\n",
    "        val beforeOffsets: List[Offset] = setBefore.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        val afterOffsets: List[Offset] = setAfter.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        if ((beforeOffsets.size >= 6) && (afterOffsets.size >= 6)) {\n",
    "\n",
    "          val midAfter = afterOffsets(afterOffsets.size / 2)\n",
    "          val midBefore = beforeOffsets(beforeOffsets.size / 2)\n",
    "\n",
    "          if (midAfter - midBefore <= 60 && midAfter > midBefore) {\n",
    "            val mid: Idx = (midAfter + midBefore) / 2\n",
    "            val right: List[String] = otherText.slice(mid - 40, mid + 40)\n",
    "\n",
    "            if (!listContainsBad(right, badWord)) {\n",
    "              //            if (true) {\n",
    "\n",
    "              val leftSlice = main.slice(offset - 25, offset + 25)\n",
    "\n",
    "              val rightSoap = right.flatMap { word =>\n",
    "                fufloList.find { bad => matchWord(word, bad) }\n",
    "              }.toSet\n",
    "\n",
    "              val leftSoap = leftSlice.flatMap { word =>\n",
    "                fufloList.find { bad => matchWord(word, bad) }\n",
    "              }.toSet\n",
    "\n",
    "              val soap = (rightSoap -- leftSoap)\n",
    "\n",
    "              val head = List(badWord, \"/\", leftSlice(25)).mkString(\"\")\n",
    "\n",
    "              val left = (leftSlice.slice(0, 25) ++ List(\"[\") ++ leftSlice.slice(25, 26) ++ List(\"]\") ++ leftSlice.slice(26, 50)).mkString(\" \")\n",
    "              val r = right.mkString(\" \")\n",
    "\n",
    "              val extraNums = s\"${beforeOffsets.size}\\t${afterOffsets.size}\\t${countNumbers(left)}\\t${countNumbers(r)}\"\n",
    "\n",
    "              Some((head, left, r, offset, soap.toList.sorted.mkString(\"||\"), extraNums))\n",
    "            } else {\n",
    "              None\n",
    "            }\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        } else {\n",
    "          None\n",
    "        }\n",
    "      }\n",
    "\n",
    "    res.sortBy(_._4).map(x => (x._5, x._1, x._2, x._3, x._6))\n",
    "  }\n",
    "\n",
    "  def fullPath1(dir: String, fileName: String): String = {\n",
    "    s\"d/data1/${dir}/$fileName\"\n",
    "  }\n",
    "\n",
    "  def mainFufloContext(mainWork: DissRef, dep: List[DissRef], fufloList: List[String]): Iterator[String] = {\n",
    "    val main: List[String] = normalize(readWoBib(fullPathDiss(mainWork, fullPath1)))\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = context(main, fufloList)\n",
    "\n",
    "    val meta = getDissMeta(mainWork.id)\n",
    "\n",
    "    dep.iterator.flatMap { otherDiss =>\n",
    "      val other: List[String] = normalize(readWoBib(fullPathDiss(otherDiss, fullPath1)))\n",
    "      val otherParse: Map[Hash, Offset] = parseWork(other)\n",
    "      val otherMeta = getDissMeta(otherDiss.id)\n",
    "\n",
    "      val check = check2Works(main, mainContext, otherParse, other)\n",
    "\n",
    "      if (check.isEmpty) {\n",
    "        List()\n",
    "      } else {\n",
    "        List(s\"${meta}\\t${otherMeta}\") ++ check.map(item => s\"\\t${item._1}\\t${item._2}\\t${item._3}\\t${item._4}\\t${item._5}\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def getDissFromRGB(id: String): DissRef = {\n",
    "    DissRef(all(s\"$id.txt\"))\n",
    "  }\n",
    "\n",
    "  lazy val fufloIds: Map[String, Int] = scala.io.Source.fromFile(\"fuflo.ids\", \"UTF-8\").getLines.map { line =>\n",
    "    val split = line.split(\"\\t\")\n",
    "    split(0) -> split(1).toInt\n",
    "  }.toMap.withDefaultValue(0)\n",
    "\n",
    "  val sciArea: Set[String] = Set(\n",
    "    \"биологических\",\n",
    "    \"медицинских\",\n",
    "    \"фармацевтических\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.toList.par.flatMap { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      val deps = ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }\n",
    "\n",
    "      mainFufloContext(mainDiss, deps.toList, fufloList)\n",
    "    } else {\n",
    "      Iterator.empty\n",
    "    }\n",
    "  }.iterator\n",
    "\n",
    "  FileUtils.write(s\"fuflo.desc.wo.v3.csv\", iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//general words set\n",
    "type Map1 = scala.collection.mutable.Map[String, Int]\n",
    "\n",
    "  val map: Map1 = scala.collection.mutable.Map[String, Int]().withDefaultValue(0)\n",
    "\n",
    "  def fileTraverse(fileName: String, map: Map1) = {\n",
    "    read(fileName).split(\" \").filter(_.size >= 5).filter(_.forall(_.isLetter)).foreach { word =>\n",
    "      val w = word.toLowerCase\n",
    "      map(w) = map(w) + 1\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "\n",
    "  def dirTraverseWords(dir: String) = {\n",
    "    println(dir)\n",
    "    FileUtils.filesInDir(dir, x => x.endsWith(\".txt\")).iterator.foreach { file =>\n",
    "      fileTraverse(file.path, map)\n",
    "    }\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  (0 to 10).foreach { idx =>\n",
    "            dirTraverseWords(s\"d/data1/$idx\")\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val sorted = map.toVector.sortBy(_._2)(Ordering[Int].reverse).filter(x => !x._1.exists(c => c >= 'a' && c <= 'z')).take(40000).iterator.map(x => s\"__label__general ${x._1}\")\n",
    "\n",
    "  FileUtils.write(\"general.txt\", sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter1 = scala.io.Source.fromFile(\"fuflo.words\", \"UTF-8\").getLines.filter { line => line.split(\"\\t\").head.toInt >= 10 }.map { line =>\n",
    "    val split = line.split(\"\\t\")\n",
    "    s\"${getDissMeta(split.last.toInt).id}\\t${split.head.toInt}\"\n",
    "  }\n",
    "\n",
    "  FileUtils.write(\"fuflo.ids\", iter1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  type Offset = Int\n",
    "  type Idx = Int\n",
    "  type Hash = (Int, Int)\n",
    "\n",
    "  def hash(str: String, seed: Int): Int = {\n",
    "    var res = 1\n",
    "    for (c <- str) {\n",
    "      res = res * seed + c.toInt\n",
    "    }\n",
    "\n",
    "    res\n",
    "  }\n",
    "\n",
    "  val fufloList: List[String] = List[String](\n",
    "    \"АФЛУБИН\",\n",
    "    \"КАГОЦЕЛ\",\n",
    "    \"АРБИДОЛ\",\n",
    "    \"АМИКСИН\",\n",
    "    \"АКТОВЕГИН\",\n",
    "    \"БЕТУЛИН\",\n",
    "    \"ВИТПРОСТ\",\n",
    "    \"ВИФЕРОН\",\n",
    "    \"ВОБЭНЗИМ\",\n",
    "    \"ГАЛАВИТ\",\n",
    "    \"ГРИППФЕРОН\",\n",
    "    \"ДЕТРАЛЕКС\",\n",
    "    \"ИМУНАЛ\",\n",
    "    \"ИМПАЗА\",\n",
    "    \"АНАФЕРОН\",\n",
    "    \"АРТРОФООН\",\n",
    "    \"ДИВАЗА\",\n",
    "    \"АФАЛА\",\n",
    "    \"АФАЛАЗА\",\n",
    "    \"ИМУНОФАН\",\n",
    "    \"ИНГАВИРИН\",\n",
    "    \"ИНГАРОН\",\n",
    "    \"ИНОЗИН\",\n",
    "    \"ИНСТЕНОН\",\n",
    "    \"ВИНПОЦЕТИН\",\n",
    "    \"КОРТЕКСИН\",\n",
    "    \"МАСТОДИНОН\",\n",
    "    \"МЕБИКАР\",\n",
    "    \"МИЛДРОНАТ\",\n",
    "    \"НОВОПАССИТ\",\n",
    "    \"ОКСОЛИН\",\n",
    "    \"ПАНАВИР\",\n",
    "    \"ПОЛИОКСИДОНИЙ\",\n",
    "    \"ПРЕДУКТАЛ\",\n",
    "    \"ПРОДИГИОЗАН\",\n",
    "    \"ТИМАЛИН\",\n",
    "    \"ТИМОГЕН\",\n",
    "    \"ТРОМБОВАЗИМ\",\n",
    "    \"ЦЕРЕБРОЛИЗИН\",\n",
    "    \"ЦИКЛОФЕРОН\",\n",
    "    \"МАГНИТОТЕРАПИЯ\",\n",
    "    \"ЛАЗЕРНОЕ ОБЛУЧЕНИЕ\",\n",
    "    \"СОЛЯНАЯ ПЕЩЕРА\",\n",
    "    \"ИРИДОДИАГНОСТИКА\",\n",
    "    \"ДИАГНОСТИКА ПО ФОЛЛЮ\",\n",
    "    \"ИГЛОТЕРАПИЯ\",\n",
    "    \"ЧЖЕНЬ ЦЗЮ ТЕРАПИЯ\",\n",
    "    \"БИОЛОГИЧЕСКАЯ ОБРАТНАЯ СВЯЗЬ\",\n",
    "    \"ГИПНОЗ\",\n",
    "    \"ГИПНОТИЧЕСКАЯ\",\n",
    "    \"ПСИХОАНАЛИЗ\",\n",
    "    \"ПСИХОАНАЛИТИЧЕСКАЯ\",\n",
    "    \"ОСТЕОПАТИЯ\",\n",
    "    \"МАНУАЛЬНАЯ ТЕРАПИЯ\",\n",
    "    \"ХИРОПРАКТИКА\",\n",
    "    \"АКУПУНКТУРА\",\n",
    "    \"ИГЛОРЕФЛЕКСОТЕРАПИЯ\",\n",
    "    \"РЕФЛЕКСОТЕРАПИЯ\",\n",
    "    \"ИГЛОУКАЛЫВАНИЕ\"\n",
    "  )\n",
    "\n",
    "  def hashT(str: String): Hash = {\n",
    "    (hash(str, 5), hash(str, 7))\n",
    "  }\n",
    "\n",
    "  lazy val windowSize = 6\n",
    "\n",
    "  def context(main: List[String], fufloList: List[String]): List[(String, Offset, Set[Hash], Set[Hash])] = {\n",
    "    val positions = fufloList.flatMap { badWord =>\n",
    "      matchList(badWord.split(\" \").toList, main, Nil, 0).map(x => (x, badWord))\n",
    "    }\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = positions.map { case (offset, badWord) =>\n",
    "      val setbefore = main.slice(offset - 25, offset).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      val setafter = main.slice(offset, offset + 25).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      (badWord, offset, setbefore, setafter)\n",
    "    }\n",
    "\n",
    "    mainContext\n",
    "  }\n",
    "\n",
    "  def parseWork(work: List[String]): Map[Hash, Offset] = {\n",
    "    work.sliding(windowSize).zipWithIndex.map { case (lst, idx) => hashT(lst.mkString(\" \")) -> idx }.toMap\n",
    "  }\n",
    "\n",
    "  def normalize(value: String): List[String] = {\n",
    "    value.filter(ch => ch == ' ' || (ch >= 'а' && ch <= 'Я') || (ch >= '\\u0410' && ch <= '\\u044F') || ch.isDigit).toUpperCase.split(\" \").filter(_.nonEmpty).toList\n",
    "  }\n",
    "\n",
    "  def listContainsBad(values: List[String], badWord: String): Boolean = {\n",
    "    matchList(badWord.split(\" \").toList, values, Nil, 0).nonEmpty\n",
    "  }\n",
    "\n",
    "  def countNumbers(value: String): Int = {\n",
    "    value.filter(ch => ch == ' ' || ch.isDigit).split(\" \").count(_.nonEmpty)\n",
    "  }\n",
    "\n",
    "  def check2Works(main: List[String], mainContext: List[(String, Offset, Set[Hash], Set[Hash])], other: Map[Hash, Offset], otherText: List[String]): List[(String, String, String, String, String)] = {\n",
    "\n",
    "    val res: List[(String, String, String, Offset, String, String)] =\n",
    "      mainContext.flatMap { case (badWord, offset, setBefore, setAfter) =>\n",
    "\n",
    "        val beforeOffsets: List[Offset] = setBefore.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        val afterOffsets: List[Offset] = setAfter.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        if ((beforeOffsets.size >= 6) && (afterOffsets.size >= 6)) {\n",
    "\n",
    "          val midAfter = afterOffsets(afterOffsets.size / 2)\n",
    "          val midBefore = beforeOffsets(beforeOffsets.size / 2)\n",
    "\n",
    "          if (midAfter - midBefore <= 60 && midAfter > midBefore) {\n",
    "            val mid: Idx = (midAfter + midBefore) / 2\n",
    "            val right: List[String] = otherText.slice(mid - 40, mid + 40)\n",
    "\n",
    "            if (!listContainsBad(right, badWord)) {\n",
    "              //            if (true) {\n",
    "\n",
    "              val leftSlice = main.slice(offset - 25, offset + 25)\n",
    "\n",
    "              val rightSoap = right.flatMap { word =>\n",
    "                fufloList.find { bad => matchWord(word, bad) }\n",
    "              }.toSet\n",
    "\n",
    "              val leftSoap = leftSlice.flatMap { word =>\n",
    "                fufloList.find { bad => matchWord(word, bad) }\n",
    "              }.toSet\n",
    "\n",
    "              val soap = (rightSoap -- leftSoap)\n",
    "\n",
    "              val head = List(badWord, \"/\", leftSlice.slice(25, 25 + badWord.split(\" \").size).mkString(\" \")).mkString(\"\")\n",
    "\n",
    "              val left = (leftSlice.slice(0, 25) ++ List(\"[\") ++ leftSlice.slice(25, 26) ++ List(\"]\") ++ leftSlice.slice(26, 50)).mkString(\" \")\n",
    "              val r = right.mkString(\" \")\n",
    "\n",
    "              val extraNums = s\"${beforeOffsets.size}\\t${afterOffsets.size}\\t${countNumbers(left)}\\t${countNumbers(r)}\"\n",
    "\n",
    "              Some((head, left, r, offset, soap.toList.sorted.mkString(\"||\"), extraNums))\n",
    "            } else {\n",
    "              None\n",
    "            }\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        } else {\n",
    "          None\n",
    "        }\n",
    "      }\n",
    "\n",
    "    res.sortBy(_._4).map(x => (x._5, x._1, x._2, x._3, x._6))\n",
    "  }\n",
    "\n",
    "  def fullPath1(dir: String, fileName: String): String = {\n",
    "    s\"d/data1/${dir}/$fileName\"\n",
    "  }\n",
    "\n",
    "  def mainFufloContext(mainWork: DissRef, dep: List[DissRef], fufloList: List[String]): Iterator[String] = {\n",
    "    val main: List[String] = normalize(readWoBib(fullPathDiss(mainWork, fullPath1), 30))\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = context(main, fufloList)\n",
    "\n",
    "    val meta = getDissMeta(mainWork.id)\n",
    "\n",
    "    dep.iterator.flatMap { otherDiss =>\n",
    "      val other: List[String] = normalize(readWoBib(fullPathDiss(otherDiss, fullPath1), 30))\n",
    "      val otherParse: Map[Hash, Offset] = parseWork(other)\n",
    "      val otherMeta = getDissMeta(otherDiss.id)\n",
    "\n",
    "      val check = check2Works(main, mainContext, otherParse, other)\n",
    "\n",
    "      if (check.isEmpty) {\n",
    "        List()\n",
    "      } else {\n",
    "        List(s\"${meta}\\t${otherMeta}\") ++ check.map(item => s\"\\t${item._1}\\t${item._2}\\t${item._3}\\t${item._4}\\t${item._5}\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def getDissFromRGB(id: String): DissRef = {\n",
    "    DissRef(all(s\"$id.txt\"))\n",
    "  }\n",
    "\n",
    "  lazy val fufloIds: Map[String, Int] = scala.io.Source.fromFile(\"fuflo.ids\", \"UTF-8\").getLines.map { line =>\n",
    "    val split = line.split(\"\\t\")\n",
    "    split(0) -> split(1).toInt\n",
    "  }.toMap.withDefaultValue(0)\n",
    "\n",
    "  val sciArea: Set[String] = Set(\n",
    "    \"биологических\",\n",
    "    \"медицинских\",\n",
    "    \"фармацевтических\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.toList.par.flatMap { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      val deps = ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }\n",
    "\n",
    "      mainFufloContext(mainDiss, deps.toList, fufloList)\n",
    "    } else {\n",
    "      Iterator.empty\n",
    "    }\n",
    "  }.iterator\n",
    "\n",
    "  FileUtils.write(s\"fuflo.desc.wo.v5.csv\", iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  type FufloPos = List[(Idx, String)]\n",
    "\n",
    "  type Offset = Int\n",
    "  type Idx = Int\n",
    "  type Hash = (Int, Int)\n",
    "\n",
    "  def hash(str: String, seed: Int): Int = {\n",
    "    var res = 1\n",
    "    for (c <- str) {\n",
    "      res = res * seed + c.toInt\n",
    "    }\n",
    "\n",
    "    res\n",
    "  }\n",
    "\n",
    "  def hashT(str: String): Hash = {\n",
    "    (hash(str, 5), hash(str, 7))\n",
    "  }\n",
    "\n",
    "  lazy val generalWords: Set[String] = {\n",
    "    scala.io.Source.fromFile(\"general.txt\", \"UTF-8\").getLines().map(_.split(\" \").last.toUpperCase()).toSet\n",
    "  }\n",
    "\n",
    "\n",
    "  lazy val windowSize = 6\n",
    "\n",
    "  def context(main: List[String], fufloPositions: List[(Idx, String)]): List[(String, Offset, Set[Hash], Set[Hash])] = {\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = fufloPositions.map { case (offset, badWord) =>\n",
    "      val setbefore = main.slice(offset - 25, offset).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      val setafter = main.slice(offset, offset + 25).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      (badWord, offset, setbefore, setafter)\n",
    "    }\n",
    "\n",
    "    mainContext\n",
    "  }\n",
    "\n",
    "  def parseWork(work: List[String]): Map[Hash, Offset] = {\n",
    "    work.sliding(windowSize).zipWithIndex.map { case (lst, idx) => hashT(lst.mkString(\" \")) -> idx }.toMap\n",
    "  }\n",
    "\n",
    "  def normalize(value: String): List[String] = {\n",
    "    value.filter(ch => ch == ' ' || (ch >= '\\u0410' && ch <= '\\u044F') || ch.isDigit).toUpperCase.split(\" \").filter(_.nonEmpty).toList\n",
    "  }\n",
    "\n",
    "  def listContainsBad(values: List[String], badWord: String): Boolean = {\n",
    "    val str = values.mkString(\"\").replace(\" \", \"\")\n",
    "    str.sliding(badWord.length, 1).exists(w => editDist(w, badWord) <= 2)\n",
    "  }\n",
    "\n",
    "  def countNumbers(value: String): Int = {\n",
    "    value.filter(ch => ch == ' ' || ch.isDigit).split(\" \").count(_.nonEmpty)\n",
    "  }\n",
    "\n",
    "  def diff(left: List[String], right: List[String]): (String, String) = {\n",
    "    val nonTLeft = left.filter(x => x.length >= 5 && !generalWords.contains(x))\n",
    "    val nonTright = right.filter(x => x.length >= 5 && !generalWords.contains(x))\n",
    "\n",
    "    val ll = nonTLeft.filter(w => !listContainsBad(right, w)).mkString(\" \")\n",
    "    val rr = nonTright.filter(w => !listContainsBad(left, w)).mkString(\" \")\n",
    "    (ll, rr)\n",
    "  }\n",
    "\n",
    "\n",
    "  def check2Works(main: List[String], mainContext: List[(String, Offset, Set[Hash], Set[Hash])], other: Map[Hash, Offset], otherText: List[String],\n",
    "                  mainFuflo: FufloPos, otherFuflo: FufloPos\n",
    "                 ): List[(String, String, String, String, String)] = {\n",
    "    val otherBadSet: Set[String] = otherFuflo.map(_._2).toSet\n",
    "    val mainBadSet: Set[String] = mainFuflo.map(_._2).toSet\n",
    "\n",
    "    val res: List[(String, String, String, Offset, String, String)] =\n",
    "      mainContext.flatMap { case (badWord, offset, setBefore, setAfter) =>\n",
    "\n",
    "        val beforeOffsets: List[Offset] = setBefore.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        val afterOffsets: List[Offset] = setAfter.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        if ((beforeOffsets.size >= 6) && (afterOffsets.size >= 6)) {\n",
    "\n",
    "          val midAfter = afterOffsets(afterOffsets.size / 2)\n",
    "          val midBefore = beforeOffsets(beforeOffsets.size / 2)\n",
    "\n",
    "          if (midAfter - midBefore <= 60 && midAfter > midBefore) {\n",
    "            val mid: Idx = (midAfter + midBefore) / 2\n",
    "            val right: List[String] = otherText.slice(mid - 40, mid + 40)\n",
    "\n",
    "            if (!listContainsBad(right, badWord) && badWord.length <= 15) {\n",
    "\n",
    "              val leftSlice: List[String] = main.slice(offset - 25, offset + 25)\n",
    "\n",
    "              val rightSoap = right.filter { word =>\n",
    "                otherBadSet.contains(word)\n",
    "              }.toSet\n",
    "\n",
    "              val leftSoap = leftSlice.filter { word =>\n",
    "                mainBadSet.contains(word)\n",
    "              }.toSet\n",
    "\n",
    "              val soap = (rightSoap -- leftSoap)\n",
    "\n",
    "              val head = List(badWord, \"/\", leftSlice.slice(25, 25 + badWord.split(\" \").size).mkString(\" \")).mkString(\"\")\n",
    "\n",
    "              val left = (leftSlice.slice(0, 25) ++ List(\"[\") ++ leftSlice.slice(25, 26) ++ List(\"]\") ++ leftSlice.slice(26, 50)).mkString(\" \")\n",
    "              val r = right.mkString(\" \")\n",
    "\n",
    "              val (ll, rr) = diff(leftSlice, right)\n",
    "              val extraNums = s\"${beforeOffsets.size}\\t${afterOffsets.size}\\t${countNumbers(left)}\\t${countNumbers(r)}\\t$ll\\t$rr\"\n",
    "\n",
    "              Some((head, left, r, offset, soap.toList.sorted.mkString(\"||\"), extraNums))\n",
    "            } else {\n",
    "              None\n",
    "            }\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        } else {\n",
    "          None\n",
    "        }\n",
    "      }\n",
    "\n",
    "    res.sortBy(_._4).map(x => (x._5, x._1, x._2, x._3, x._6))\n",
    "  }\n",
    "\n",
    "  def fullPath1(dir: String, fileName: String): String = {\n",
    "    s\"d/data1/${dir}/$fileName\"\n",
    "  }\n",
    "\n",
    "  val url = \"http://172.16.253.4:9875/pred\"\n",
    "\n",
    "  def mainFufloContext(mainWork: DissRef, dep: List[DissRef]): Iterator[String] = {\n",
    "    val main: List[String] = normalize(readWoBib(fullPathDiss(mainWork, fullPath1), 30))\n",
    "\n",
    "    val mainFuflo: List[(Idx, String)] = req(main.mkString(\" \"), url)\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = context(main, mainFuflo)\n",
    "\n",
    "    val meta = getDissMeta(mainWork.id)\n",
    "\n",
    "    dep.iterator.flatMap { otherDiss =>\n",
    "      val other: List[String] = normalize(readWoBib(fullPathDiss(otherDiss, fullPath1), 30))\n",
    "      val otherFuflo: List[(Idx, String)] = req(other.mkString(\" \"), url)\n",
    "\n",
    "      val otherParse: Map[Hash, Offset] = parseWork(other)\n",
    "      val otherMeta = getDissMeta(otherDiss.id)\n",
    "\n",
    "      val check = check2Works(main, mainContext, otherParse, other, mainFuflo, otherFuflo)\n",
    "\n",
    "      if (check.isEmpty) {\n",
    "        List()\n",
    "      } else {\n",
    "        List(s\"${meta}\\t${otherMeta}\") ++ check.map(item => s\"\\t${item._1}\\t${item._2}\\t${item._3}\\t${item._4}\\t${item._5}\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def getDissFromRGB(id: String): DissRef = {\n",
    "    DissRef(all(s\"$id.txt\"))\n",
    "  }\n",
    "\n",
    "  lazy val fufloIds: Map[String, Int] = scala.io.Source.fromFile(\"fuflo.ids\", \"UTF-8\").getLines.map { line =>\n",
    "    val split = line.split(\"\\t\")\n",
    "    split(0) -> split(1).toInt\n",
    "  }.toMap.withDefaultValue(0)\n",
    "\n",
    "  val sciArea: Set[String] = Set(\n",
    "    \"биологических\",\n",
    "    \"медицинских\",\n",
    "    \"фармацевтических\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.iterator.flatMap { case (mainId, _) =>\n",
    "//  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.toList.par.flatMap { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      val deps = ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }\n",
    "\n",
    "      mainFufloContext(mainDiss, deps.toList)\n",
    "    } else {\n",
    "      Iterator.empty\n",
    "    }\n",
    "  }\n",
    "\n",
    "  FileUtils.write(s\"fuflo.desc.wo.v7.csv\", iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req(\"АРБИДОЛ СВОДОБУ ПОЛИТЗАКЛЮЧЕННЫМ\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.toList.par.flatMap { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      val deps = ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }\n",
    "\n",
    "      mainFufloContext(mainDiss, deps.toList)\n",
    "    } else {\n",
    "      Iterator.empty\n",
    "    }\n",
    "  }.iterator\n",
    "\n",
    "  FileUtils.write(s\"fuflo.desc.wo.v6.csv\", iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val set = scala.collection.mutable.Set[DissRef]()\n",
    "\n",
    "  fufloIds.filter { case (_, value) => value >= 10 }.foreach { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      set.add(mainDiss)\n",
    "\n",
    "      ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }.foreach(set.add)\n",
    "\n",
    "    }\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  set.toVector.foreach { diss =>\n",
    "    val text = normalize(readWoBib(fullPathDiss(diss, fullPath1), 30))\n",
    "    val res: List[(Int, String)] = req(text.mkString(\" \"), url)\n",
    "    val r = res.map(x => s\"${x._1}|${x._2}\").mkString(\"/\")\n",
    "\n",
    "    val s = s\"${diss.id}\\t$r\"\n",
    "    FileUtils.appendLine(\"medcache.txt\", s)\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//   lazy val medicineCache: Map[Int, List[(Int, String)]] = {\n",
    "//     scala.io.Source.fromFile(\"medcache.txt\", \"UTF-8\").getLines().map { line =>\n",
    "//       val split = line.split(\"\\t\")\n",
    "//       val id = split.head.toInt\n",
    "\n",
    "//       val other: List[(Idx, String)] = split.last.split(\"/\").map { item =>\n",
    "//         val split = item.split(\"\\\\|\")\n",
    "//         split.head.toInt -> split.last\n",
    "//       }.toList.filter(x => !generalWords.contains(x._2))\n",
    "\n",
    "//       id -> other\n",
    "//     }.toMap.withDefaultValue(Nil)\n",
    "//   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicineCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  type FufloPos = List[(Idx, String)]\n",
    "\n",
    "  type Offset = Int\n",
    "  type Idx = Int\n",
    "  type Hash = (Int, Int)\n",
    "\n",
    "  def hash(str: String, seed: Int): Int = {\n",
    "    var res = 1\n",
    "    for (c <- str) {\n",
    "      res = res * seed + c.toInt\n",
    "    }\n",
    "\n",
    "    res\n",
    "  }\n",
    "\n",
    "  def hashT(str: String): Hash = {\n",
    "    (hash(str, 5), hash(str, 7))\n",
    "  }\n",
    "\n",
    "  lazy val windowSize = 6\n",
    "\n",
    "  def context(main: List[String], fufloPositions: List[(Idx, String)]): List[(String, Offset, Set[Hash], Set[Hash])] = {\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = fufloPositions.map { case (offset, badWord) =>\n",
    "      val setbefore = main.slice(offset - 25, offset).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      val setafter = main.slice(offset, offset + 25).sliding(windowSize).map(x => hashT(x.mkString(\" \"))).toSet\n",
    "      (badWord, offset, setbefore, setafter)\n",
    "    }\n",
    "\n",
    "    mainContext\n",
    "  }\n",
    "\n",
    "  def parseWork(work: List[String]): Map[Hash, Offset] = {\n",
    "    work.sliding(windowSize).zipWithIndex.map { case (lst, idx) => hashT(lst.mkString(\" \")) -> idx }.toMap\n",
    "  }\n",
    "\n",
    "  def normalize(value: String): List[String] = {\n",
    "    value.filter(ch => ch == ' ' || (ch >= '\\u0410' && ch <= '\\u044F') || ch.isDigit).toUpperCase.split(\" \").filter(_.nonEmpty).toList\n",
    "  }\n",
    "\n",
    "  def listContainsBad(values: List[String], badWord: String): Boolean = {\n",
    "    val str = values.mkString(\"\").replace(\" \", \"\")\n",
    "    str.sliding(badWord.length, 1).exists(w => editDist(w, badWord) <= 2)\n",
    "  }\n",
    "\n",
    "  def countNumbers(value: String): Int = {\n",
    "    value.filter(ch => ch == ' ' || ch.isDigit).split(\" \").count(_.nonEmpty)\n",
    "  }\n",
    "\n",
    "  def diff(left: List[String], right: List[String]): (String, String) = {\n",
    "    val nonTLeft = left.filter(x => x.length >= 5 && !generalWords.contains(x))\n",
    "    val nonTright = right.filter(x => x.length >= 5 && !generalWords.contains(x))\n",
    "\n",
    "    val ll = nonTLeft.filter(w => !listContainsBad(right, w)).mkString(\" \")\n",
    "    val rr = nonTright.filter(w => !listContainsBad(left, w)).mkString(\" \")\n",
    "    (ll, rr)\n",
    "  }\n",
    "\n",
    "\n",
    "  def check2Works(main: List[String], mainContext: List[(String, Offset, Set[Hash], Set[Hash])], other: Map[Hash, Offset], otherText: List[String],\n",
    "                  mainFuflo: FufloPos, otherFuflo: FufloPos\n",
    "                 ): List[(String, String, String, String, String)] = {\n",
    "    val otherBadSet: Set[String] = otherFuflo.map(_._2).toSet\n",
    "    val mainBadSet: Set[String] = mainFuflo.map(_._2).toSet\n",
    "\n",
    "    val res: List[(String, String, String, Offset, String, String)] =\n",
    "      mainContext.flatMap { case (badWord, offset, setBefore, setAfter) =>\n",
    "\n",
    "        val beforeOffsets: List[Offset] = setBefore.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        val afterOffsets: List[Offset] = setAfter.flatMap { hash =>\n",
    "          if (other.contains(hash)) {\n",
    "            Some(other(hash))\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        }.toList.sorted\n",
    "\n",
    "        if ((beforeOffsets.size >= 6) && (afterOffsets.size >= 6)) {\n",
    "\n",
    "          val midAfter = afterOffsets(afterOffsets.size / 2)\n",
    "          val midBefore = beforeOffsets(beforeOffsets.size / 2)\n",
    "          val leftSlice: List[String] = main.slice(offset - 25, offset + 25)\n",
    "\n",
    "          if (midAfter - midBefore <= 60 && midAfter > midBefore) {\n",
    "            val mid: Idx = (midAfter + midBefore) / 2\n",
    "            val right: List[String] = otherText.slice(mid - 40, mid + 40)\n",
    "\n",
    "            val medicineInRight = otherFuflo.filter(x => java.lang.Math.abs(mid - x._1) <= 7).map(_._2)\n",
    "\n",
    "            val replacedInRight = medicineInRight.filter(word => listContainsBad(leftSlice, word))\n",
    "\n",
    "            if (!listContainsBad(right, badWord) && badWord.length <= 15 && replacedInRight.nonEmpty) {\n",
    "\n",
    "              val rightSoap = right.filter { word =>\n",
    "                otherBadSet.contains(word)\n",
    "              }.toSet\n",
    "\n",
    "              val leftSoap = leftSlice.filter { word =>\n",
    "                mainBadSet.contains(word)\n",
    "              }.toSet\n",
    "\n",
    "              val soap = (rightSoap -- leftSoap)\n",
    "\n",
    "              val head = List(badWord, \"/\", leftSlice.slice(25, 25 + badWord.split(\" \").size).mkString(\" \")).mkString(\"\")\n",
    "\n",
    "              val left = (leftSlice.slice(0, 25) ++ List(\"[\") ++ leftSlice.slice(25, 26) ++ List(\"]\") ++ leftSlice.slice(26, 50)).mkString(\" \")\n",
    "              val r = right.mkString(\" \")\n",
    "\n",
    "              val (ll, rr) = diff(leftSlice, right)\n",
    "              val extraNums = s\"${beforeOffsets.size}\\t${afterOffsets.size}\\t${countNumbers(left)}\\t${countNumbers(r)}\\t$ll\\t$rr\\t${replacedInRight.mkString(\",\")}\"\n",
    "\n",
    "              Some((head, left, r, offset, soap.toList.sorted.mkString(\"||\"), extraNums))\n",
    "            } else {\n",
    "              None\n",
    "            }\n",
    "          } else {\n",
    "            None\n",
    "          }\n",
    "        } else {\n",
    "          None\n",
    "        }\n",
    "      }\n",
    "\n",
    "    res.sortBy(_._4).map(x => (x._5, x._1, x._2, x._3, x._6))\n",
    "  }\n",
    "\n",
    "  def fullPath1(dir: String, fileName: String): String = {\n",
    "    s\"d/data1/${dir}/$fileName\"\n",
    "  }\n",
    "\n",
    "  def mainFufloContext(mainWork: DissRef, dep: List[DissRef]): Iterator[String] = {\n",
    "    val main: List[String] = normalize(readWoBib(fullPathDiss(mainWork, fullPath1), 30))\n",
    "\n",
    "    val mainFuflo: List[(Idx, String)] = medicineCache(mainWork.id)\n",
    "\n",
    "    val mainContext: List[(String, Offset, Set[Hash], Set[Hash])] = context(main, mainFuflo)\n",
    "\n",
    "    val meta = getDissMeta(mainWork.id)\n",
    "\n",
    "    dep.iterator.flatMap { otherDiss =>\n",
    "      val other: List[String] = normalize(readWoBib(fullPathDiss(otherDiss, fullPath1), 30))\n",
    "\n",
    "      val otherFuflo: List[(Idx, String)] = medicineCache(otherDiss.id)\n",
    "\n",
    "      val otherParse: Map[Hash, Offset] = parseWork(other)\n",
    "      val otherMeta = getDissMeta(otherDiss.id)\n",
    "\n",
    "      val check = check2Works(main, mainContext, otherParse, other, mainFuflo, otherFuflo)\n",
    "\n",
    "      if (check.isEmpty) {\n",
    "        List()\n",
    "      } else {\n",
    "        List(s\"${meta}\\t${otherMeta}\") ++ check.map(item => s\"\\t${item._1}\\t${item._2}\\t${item._3}\\t${item._4}\\t${item._5}\")\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def getDissFromRGB(id: String): DissRef = {\n",
    "    DissRef(all(s\"$id.txt\"))\n",
    "  }\n",
    "\n",
    "  lazy val fufloIds: Map[String, Int] = scala.io.Source.fromFile(\"fuflo.ids\", \"UTF-8\").getLines.map { line =>\n",
    "    val split = line.split(\"\\t\")\n",
    "    split(0) -> split(1).toInt\n",
    "  }.toMap.withDefaultValue(0)\n",
    "\n",
    "  val sciArea: Set[String] = Set(\n",
    "    \"биологических\",\n",
    "    \"медицинских\",\n",
    "    \"фармацевтических\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  val iter: Iterator[String] = fufloIds.filter { case (_, value) => value >= 10 }.toList.par.flatMap { case (mainId, _) =>\n",
    "    val mainMeta = meta2(mainId)\n",
    "\n",
    "    if (mainMeta._type == \"disser\" && sciArea.contains(mainMeta.sciArea)) {\n",
    "\n",
    "      val mainDiss: DissRef = getDissFromRGB(mainMeta.id)\n",
    "\n",
    "      val deps = ngGrouped(mainDiss).collect {\n",
    "        case x@DissRef(_) => x\n",
    "      }.filter { other =>\n",
    "        val otherMeta = getDissMeta(other.id)\n",
    "        otherMeta.lastName != mainMeta.lastName && otherMeta._type == \"disser\"\n",
    "      }\n",
    "\n",
    "      mainFufloContext(mainDiss, deps.toList)\n",
    "    } else {\n",
    "      Iterator.empty\n",
    "    }\n",
    "  }.iterator\n",
    "\n",
    "  FileUtils.write(s\"fuflo.desc.wo.v9.csv\", iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
